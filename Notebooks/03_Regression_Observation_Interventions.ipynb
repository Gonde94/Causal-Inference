{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1b2c6e",
   "metadata": {},
   "source": [
    "### Regression, Observations, and Interventions\n",
    "\n",
    "This chapter builds a link between associations, interventions, and regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7876477",
   "metadata": {},
   "source": [
    "<b>Linear regression</b> is a basic data-fitting algorithm that can be used to predict the expected value of a dependent (target) variable, Y, given values of some predictor(s), X. Formally, this is:\n",
    "- Yhat<sub>X = x</sub> = E[Y | X = x].\n",
    "\n",
    "An important feature of linear regression is that it allows us to easily quantify the strength of the relationship between predictors and the target variable by computing regression coefficients. Regression coefficients can be thought of as the amount of change in the <i>predicted</i> output variable relative to a unit change in the input variable. \n",
    "\n",
    "As an example, a model with one predictor, x. First, we define the data-generating process. We'll make this process follow the linear regression formula (Yhat<sub>i</sub> = a + bx<sub>i</sub>) and assign arbitrary values to the (true) parameters a* and b*. We will also add noise to the model and mark it as e (this will be normally distributed with zero mean and a standard deviation of 1). Additionally we will scale e by 0.5. So the data-generating formula becomes: \n",
    "- yhat<sub>i</sub> = 1.12 + 0.93x<sub>i</sub> + 0.5e<sub>i</sub>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
